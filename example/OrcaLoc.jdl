#Sample jdl (job description lanaguage) configuration for gross analysis

#==> General Orca job options

#Owner and dataset to be analyzed - Datachain lists other filetypes required
Owner = "hg_DST871_2x1033PU_g133_OSC";
Dataset = "hg03_hsm120_mumu";

#DataChain = "DST";
DataChain ="DST,Digi,Hit";

#Executable to use - ORCA version automatically determined after eval `scram runtime -sh`
#and any argumments except -c orcarc 
Executable = "ExDSTStatistics";
Orcarc = "/afs/cern.ch/user/s/swakef/gross-v0_4_0/orcarc";
Arguments = "";

#If not specifed takes first and last from RefDB
#FirstRun = "66100021";
#LastRun = "66100025";

#For job Spliting - how many runs to analyze in each job
RunsPerJob = "4";

#Suffix to add to job files - aids identification - Optional
OutFileSuffix = "myHiggsAnalysis";

#Input data - anything other than orcarc and exe/libs
#InputSandbox  = {"input_data_file"};

#Output data - ie root files, returned to local file system (from grid and local jobs)
OutputSandbox = {"dststatistics.aida"};

#Name for std output and error
StdOutput     = "mystandardout.out";
StdError      = "mystandarderr.err";


#==> scheduler specific options

#Note any options here not known to GROSS will be passed down to BOSS and eventually to the scheduler

#Local Batch systems (ie LSF or PBS)

 #Need scram location not needed in grid jobs 
 Scram = "/afs/cern.ch/cms/utils/scram";
 
 #LSF queue to submit to 
 LSFQueue = "1nd";
 
 #Any extra pool catalogs not in PubDB - full POOL contact string
 ExtraPoolCatalogs = {"xmlcatalog_http://cmsdoc.cern.ch/cms/production/publish/PRS/DC04/jm_2x1033PU761_TkMu_2_g133_OSC/jm03b_qcd_50_80/POOL_Catalogue_PCP.jm_2x1033PU761_TkMu_2_g133_OSC.jm03b_qcd_50_80.xml", "xmlcatalog_file:/home/stuartw/gross-v0_4_1/example/POOL_Catalogue_PCP.jm_2x1033PU761_TkMu_2_g133_OSC.jm03b_qcd_50_80.xml"};

